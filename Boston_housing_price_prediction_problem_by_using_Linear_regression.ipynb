{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "id": "Gfst71Rbh5zR",
    "outputId": "f294adb6-16a6-4c4b-c782-2f8759ec31a9"
   },
   "outputs": [],
   "source": [
    "#from sklearn.datasets import load_boston\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "#boston_dataset = load_boston()\n",
    "\n",
    "#google collab upload dataset\n",
    "#from google.colab import files\n",
    "#uploaded = files.upload()\n",
    "#import io\n",
    "\n",
    "# Check the uploaded file name\n",
    "#uploaded_file_name = list(uploaded.keys())[0]\n",
    "\n",
    "# Read the uploaded file using the correct name\n",
    "#df = pd.read_csv(io.BytesIO(uploaded[uploaded_file_name]))\n",
    "\n",
    "df = pd.read_csv(\"Boston.csv\")\n",
    "df.columns = [' ','crim','zn','indus','chas','nox','rm', 'age' , 'dis', 'rad' , 'tax', 'ptratio', 'black', 'lstat', 'medv']\n",
    "df\n",
    "\n",
    "import warnings\n",
    "#We do not want to see warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mGhV-iJth8cE",
    "outputId": "6729ed4f-cc31-4a9d-d344-fa4d07c3548b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(354, 14)\n",
      "(152, 14)\n",
      "(354,)\n",
      "(152,)\n",
      "             int64\n",
      "crim       float64\n",
      "zn         float64\n",
      "indus      float64\n",
      "chas         int64\n",
      "nox        float64\n",
      "rm         float64\n",
      "age        float64\n",
      "dis        float64\n",
      "rad          int64\n",
      "tax          int64\n",
      "ptratio    float64\n",
      "black      float64\n",
      "lstat      float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.drop('medv', axis=1)\n",
    "y = df['medv']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=123)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "# Check for missing values\n",
    "missing_values = X_train.isnull().sum()\n",
    "\n",
    "\n",
    "# Check the data types\n",
    "print(X_train.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mruwckhwh_Hr",
    "outputId": "3a8e51ae-8820-48ac-f52c-42bc9fa25879"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(354, 14)\n",
      "(152, 14)\n",
      "(354,)\n",
      "(152,)\n"
     ]
    }
   ],
   "source": [
    "#Normalization or std. scalar - data preprocessing\n",
    "#from sklearn.preprocessing import MinMaxScaler\n",
    "#scaler = MinMaxScaler()\n",
    "#X_train=scaler.fit_transform(X_train)\n",
    "#X_test=scaler.fit_transform(X_test)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N7yjTunhiCaz",
    "outputId": "ea1b1a6b-cdf1-4353-eacc-d8f3c42b7e1c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,920</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │           \u001b[38;5;34m1,920\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m8,256\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m4,160\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m4,160\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m4,160\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_output (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m65\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">22,721</span> (88.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m22,721\u001b[0m (88.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">22,721</span> (88.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m22,721\u001b[0m (88.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_shape=(14, ), activation='sigmoid', name='dense_1'))\n",
    "#model.add(Dense(128, input_shape=(13, ), activation='relu', name='dense_1'))\n",
    "model.add(Dense(64, activation='relu', name='dense_2'))\n",
    "model.add(Dense(64, activation='relu', name='dense_3'))\n",
    "model.add(Dense(64, activation='relu', name='dense_4'))\n",
    "model.add(Dense(64, activation='relu', name='dense_5'))\n",
    "model.add(Dense(1, activation='linear', name='dense_output'))\n",
    "#model.compile(optimizer='RMSprop', loss='mse', metrics=['mae'])\n",
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.001), loss='mse', metrics=['mae'])\n",
    "model.summary()\n",
    "for layer in model.layers:\n",
    "   if layer.name.startswith('pre_trained_model'):\n",
    "      layer.trainable = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p_l00hwSkmYL",
    "outputId": "30d00126-2e52-4d9d-a02c-919224bcfaee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 556.1948 - mae: 21.7580 - val_loss: 376.8523 - val_mae: 17.2209\n",
      "Epoch 2/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 297.8494 - mae: 14.6419 - val_loss: 100.8035 - val_mae: 6.7680\n",
      "Epoch 3/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 74.4508 - mae: 5.8971 - val_loss: 63.0704 - val_mae: 6.6084\n",
      "Epoch 4/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 58.6019 - mae: 5.5991 - val_loss: 60.9647 - val_mae: 5.8281\n",
      "Epoch 5/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 58.0701 - mae: 5.5200 - val_loss: 58.2287 - val_mae: 5.7678\n",
      "Epoch 6/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 50.5485 - mae: 5.0377 - val_loss: 54.5675 - val_mae: 6.0120\n",
      "Epoch 7/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 49.7890 - mae: 5.1274 - val_loss: 62.5404 - val_mae: 5.4038\n",
      "Epoch 8/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 49.6407 - mae: 4.7678 - val_loss: 53.8134 - val_mae: 6.5859\n",
      "Epoch 9/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 48.8650 - mae: 5.0682 - val_loss: 58.5903 - val_mae: 5.2444\n",
      "Epoch 10/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 41.2114 - mae: 4.4642 - val_loss: 55.9546 - val_mae: 5.1016\n",
      "Epoch 11/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 43.9902 - mae: 4.3580 - val_loss: 56.9256 - val_mae: 4.9797\n",
      "Epoch 12/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 38.0401 - mae: 4.2589 - val_loss: 66.1666 - val_mae: 4.8295\n",
      "Epoch 13/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 37.1572 - mae: 3.9966 - val_loss: 46.3491 - val_mae: 5.6118\n",
      "Epoch 14/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 32.7525 - mae: 4.1705 - val_loss: 55.1415 - val_mae: 4.5379\n",
      "Epoch 15/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 26.5882 - mae: 3.4323 - val_loss: 44.6354 - val_mae: 5.6492\n",
      "Epoch 16/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 27.2648 - mae: 3.7739 - val_loss: 44.3419 - val_mae: 5.5224\n",
      "Epoch 17/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 26.3953 - mae: 3.7844 - val_loss: 71.1536 - val_mae: 5.4984\n",
      "Epoch 18/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 31.4330 - mae: 3.6956 - val_loss: 42.7700 - val_mae: 4.7474\n",
      "Epoch 19/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 24.3189 - mae: 3.6041 - val_loss: 42.4431 - val_mae: 4.6231\n",
      "Epoch 20/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 30.0011 - mae: 3.8017 - val_loss: 41.6353 - val_mae: 4.8471\n",
      "Epoch 21/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 22.5818 - mae: 3.2817 - val_loss: 51.9514 - val_mae: 6.3112\n",
      "Epoch 22/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 31.8590 - mae: 4.2910 - val_loss: 41.2693 - val_mae: 4.2805\n",
      "Epoch 23/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 20.3858 - mae: 3.2208 - val_loss: 44.9719 - val_mae: 3.9867\n",
      "Epoch 24/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 23.8314 - mae: 3.2000 - val_loss: 70.3424 - val_mae: 5.7832\n",
      "Epoch 25/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 25.8841 - mae: 3.5802 - val_loss: 53.8463 - val_mae: 4.2479\n",
      "Epoch 26/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 24.6931 - mae: 3.3106 - val_loss: 62.2002 - val_mae: 5.1051\n",
      "Epoch 27/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 20.9609 - mae: 3.0219 - val_loss: 38.8335 - val_mae: 4.2683\n",
      "Epoch 28/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 19.0708 - mae: 3.2505 - val_loss: 57.8894 - val_mae: 4.7300\n",
      "Epoch 29/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 29.3265 - mae: 3.9175 - val_loss: 40.9764 - val_mae: 3.8645\n",
      "Epoch 30/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 21.4410 - mae: 3.0589 - val_loss: 57.3135 - val_mae: 4.7707\n",
      "Epoch 31/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 14.3380 - mae: 2.7480 - val_loss: 36.4866 - val_mae: 4.1001\n",
      "Epoch 32/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 28.1631 - mae: 3.8772 - val_loss: 36.5580 - val_mae: 3.9092\n",
      "Epoch 33/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 19.4913 - mae: 3.0227 - val_loss: 40.3118 - val_mae: 3.5777\n",
      "Epoch 34/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 17.9137 - mae: 2.7666 - val_loss: 42.8959 - val_mae: 3.7867\n",
      "Epoch 35/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 26.9335 - mae: 3.5605 - val_loss: 35.4755 - val_mae: 3.6936\n",
      "Epoch 36/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 20.7857 - mae: 3.1924 - val_loss: 38.8909 - val_mae: 3.5262\n",
      "Epoch 37/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 15.5735 - mae: 2.6421 - val_loss: 37.6865 - val_mae: 5.0148\n",
      "Epoch 38/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 25.7668 - mae: 3.9287 - val_loss: 33.8724 - val_mae: 4.0072\n",
      "Epoch 39/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 16.9174 - mae: 2.8673 - val_loss: 33.0376 - val_mae: 3.4280\n",
      "Epoch 40/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 17.9769 - mae: 2.7862 - val_loss: 31.8357 - val_mae: 3.4033\n",
      "Epoch 41/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 18.0870 - mae: 3.0192 - val_loss: 31.0537 - val_mae: 3.4745\n",
      "Epoch 42/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 12.0526 - mae: 2.3721 - val_loss: 37.0734 - val_mae: 3.4207\n",
      "Epoch 43/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 22.6126 - mae: 3.3409 - val_loss: 33.2701 - val_mae: 3.3543\n",
      "Epoch 44/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 18.2553 - mae: 2.7242 - val_loss: 41.4078 - val_mae: 3.7998\n",
      "Epoch 45/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 15.2834 - mae: 2.6336 - val_loss: 37.9660 - val_mae: 3.5933\n",
      "Epoch 46/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 14.0967 - mae: 2.4561 - val_loss: 31.5962 - val_mae: 3.0987\n",
      "Epoch 47/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 10.7871 - mae: 2.2732 - val_loss: 41.5002 - val_mae: 5.7280\n",
      "Epoch 48/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 30.4636 - mae: 4.1327 - val_loss: 32.9769 - val_mae: 3.1500\n",
      "Epoch 49/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 13.0264 - mae: 2.3583 - val_loss: 31.0031 - val_mae: 2.9886\n",
      "Epoch 50/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 12.0971 - mae: 2.2629 - val_loss: 43.9523 - val_mae: 4.3220\n",
      "Epoch 51/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 20.0087 - mae: 3.2741 - val_loss: 37.0648 - val_mae: 5.4606\n",
      "Epoch 52/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 25.0264 - mae: 3.8482 - val_loss: 28.8363 - val_mae: 3.2619\n",
      "Epoch 53/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 10.5582 - mae: 2.1863 - val_loss: 29.7724 - val_mae: 4.3135\n",
      "Epoch 54/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 17.7629 - mae: 3.0914 - val_loss: 27.4345 - val_mae: 3.8315\n",
      "Epoch 55/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 13.6747 - mae: 2.5943 - val_loss: 28.5814 - val_mae: 3.9365\n",
      "Epoch 56/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 21.4216 - mae: 3.3543 - val_loss: 26.5543 - val_mae: 3.1197\n",
      "Epoch 57/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 13.9921 - mae: 2.3634 - val_loss: 26.1670 - val_mae: 3.1840\n",
      "Epoch 58/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 14.7607 - mae: 2.4563 - val_loss: 27.0111 - val_mae: 3.1914\n",
      "Epoch 59/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 20.2412 - mae: 2.9877 - val_loss: 31.2682 - val_mae: 3.2686\n",
      "Epoch 60/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 12.2030 - mae: 2.3012 - val_loss: 25.0689 - val_mae: 3.5868\n",
      "Epoch 61/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 17.3341 - mae: 3.0026 - val_loss: 31.2657 - val_mae: 4.7967\n",
      "Epoch 62/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 23.2419 - mae: 3.5396 - val_loss: 24.6614 - val_mae: 3.0127\n",
      "Epoch 63/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 13.9121 - mae: 2.3507 - val_loss: 42.0101 - val_mae: 4.4122\n",
      "Epoch 64/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 11.7270 - mae: 2.4700 - val_loss: 25.0752 - val_mae: 3.9271\n",
      "Epoch 65/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 17.2272 - mae: 3.1702 - val_loss: 26.1243 - val_mae: 2.9565\n",
      "Epoch 66/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 10.4876 - mae: 2.0963 - val_loss: 26.3306 - val_mae: 2.6143\n",
      "Epoch 67/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 15.0999 - mae: 2.8130 - val_loss: 33.8265 - val_mae: 3.5283\n",
      "Epoch 68/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 10.9987 - mae: 2.4123 - val_loss: 26.7665 - val_mae: 4.3670\n",
      "Epoch 69/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 18.3869 - mae: 3.2854 - val_loss: 28.7316 - val_mae: 3.2422\n",
      "Epoch 70/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 11.3569 - mae: 2.3691 - val_loss: 24.6189 - val_mae: 3.9177\n",
      "Epoch 71/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 17.1414 - mae: 2.8289 - val_loss: 30.3462 - val_mae: 3.2069\n",
      "Epoch 72/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 13.7568 - mae: 2.5300 - val_loss: 28.3486 - val_mae: 3.0742\n",
      "Epoch 73/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 15.4385 - mae: 2.7190 - val_loss: 25.5667 - val_mae: 2.8946\n",
      "Epoch 74/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 15.4061 - mae: 2.4942 - val_loss: 20.2761 - val_mae: 3.3436\n",
      "Epoch 75/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 17.0268 - mae: 2.8495 - val_loss: 21.3734 - val_mae: 3.4342\n",
      "Epoch 76/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 13.9756 - mae: 2.5657 - val_loss: 20.7766 - val_mae: 3.4864\n",
      "Epoch 77/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 13.2156 - mae: 2.5321 - val_loss: 23.3238 - val_mae: 2.3915\n",
      "Epoch 78/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 12.1130 - mae: 2.3601 - val_loss: 33.3770 - val_mae: 3.8592\n",
      "Epoch 79/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 25.3958 - mae: 3.1988 - val_loss: 23.8218 - val_mae: 2.6717\n",
      "Epoch 80/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 18.5852 - mae: 2.5492 - val_loss: 20.6698 - val_mae: 2.8237\n",
      "Epoch 81/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 14.5652 - mae: 2.4907 - val_loss: 19.1024 - val_mae: 2.8475\n",
      "Epoch 82/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 14.5774 - mae: 2.4668 - val_loss: 21.1952 - val_mae: 2.6527\n",
      "Epoch 83/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 14.2874 - mae: 2.3743 - val_loss: 24.1194 - val_mae: 4.0294\n",
      "Epoch 84/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 17.9054 - mae: 3.1750 - val_loss: 23.3302 - val_mae: 2.5251\n",
      "Epoch 85/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 11.7634 - mae: 2.3498 - val_loss: 22.5398 - val_mae: 2.4895\n",
      "Epoch 86/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 14.0866 - mae: 2.5380 - val_loss: 20.4146 - val_mae: 2.7717\n",
      "Epoch 87/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 11.8168 - mae: 2.2857 - val_loss: 17.4452 - val_mae: 2.8662\n",
      "Epoch 88/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 13.2011 - mae: 2.2566 - val_loss: 22.4971 - val_mae: 3.8269\n",
      "Epoch 89/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 20.9893 - mae: 3.1132 - val_loss: 19.0954 - val_mae: 2.4659\n",
      "Epoch 90/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 11.0156 - mae: 2.1577 - val_loss: 19.3891 - val_mae: 2.3116\n",
      "Epoch 91/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 11.7836 - mae: 2.2224 - val_loss: 32.5241 - val_mae: 3.9032\n",
      "Epoch 92/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 21.5669 - mae: 3.1334 - val_loss: 18.4683 - val_mae: 3.2302\n",
      "Epoch 93/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 15.0499 - mae: 2.9202 - val_loss: 16.6604 - val_mae: 2.8256\n",
      "Epoch 94/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 10.8703 - mae: 2.1977 - val_loss: 27.2788 - val_mae: 3.3422\n",
      "Epoch 95/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 12.2647 - mae: 2.3231 - val_loss: 20.1783 - val_mae: 3.6530\n",
      "Epoch 96/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 21.1502 - mae: 3.2956 - val_loss: 18.5278 - val_mae: 2.4194\n",
      "Epoch 97/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 14.3625 - mae: 2.4766 - val_loss: 15.9626 - val_mae: 3.0067\n",
      "Epoch 98/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 11.4694 - mae: 2.3816 - val_loss: 22.3901 - val_mae: 2.6092\n",
      "Epoch 99/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 22.9992 - mae: 3.0264 - val_loss: 27.1220 - val_mae: 3.4193\n",
      "Epoch 100/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 12.0688 - mae: 2.4360 - val_loss: 20.6641 - val_mae: 2.4210\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, batch_size = 64, epochs=100, validation_split= 0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0G-utiHylACz",
    "outputId": "ed7e5cb7-664d-4504-97ba-3caad8292973"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 33.8118 - mae: 3.3162 \n",
      "Mean squared error on test data:  23.098495483398438\n",
      "Mean absolute error on test data:  2.898577928543091\n"
     ]
    }
   ],
   "source": [
    "mse_nn, mae_nn = model.evaluate(X_test, y_test)\n",
    "\n",
    "print('Mean squared error on test data: ', mse_nn)\n",
    "print('Mean absolute error on test data: ', mae_nn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explaination:\n",
    "\n",
    "1. Importing Libraries and Modules\n",
    "```python\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "```\n",
    "- **Explanation:** This section imports necessary libraries and modules for data manipulation, machine learning, and deep learning. `numpy` and `pandas` are used for data handling, `train_test_split` from `sklearn.model_selection` is used for splitting data into training and testing sets, `StandardScaler` from `sklearn.preprocessing` is for standardizing the data, and `tensorflow` with `tf.keras` is used for building and training neural networks.\n",
    "\n",
    "2. Loading and Preparing Data\n",
    "```python\n",
    "df = pd.read_csv(\"Boston.csv\")\n",
    "df.columns = [' ','crim','zn','indus','chas','nox','rm', 'age' , 'dis', 'rad' , 'tax', 'ptratio', 'black', 'lstat', 'medv']\n",
    "X = df.drop('medv', axis=1)\n",
    "y = df['medv']\n",
    "```\n",
    "- **Explanation:** This section reads data from a CSV file named `\"Boston.csv\"` into a pandas DataFrame (`df`). It then assigns meaningful column names to the DataFrame. Features (`X`) are selected by dropping the target variable (`medv`), and the target variable (`y`) is isolated.\n",
    "\n",
    "3. Data Splitting\n",
    "```python\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=123)\n",
    "```\n",
    "- **Explanation:** This part splits the data into training (`X_train`, `y_train`) and testing (`X_test`, `y_test`) sets using `train_test_split` from `sklearn.model_selection`. The split ratio is set to 70% for training and 30% for testing.\n",
    "\n",
    "4. Data Preprocessing\n",
    "```python\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "```\n",
    "- **Explanation:** Here, `StandardScaler` is used to standardize the features (`X_train`, `X_test`) by removing the mean and scaling to unit variance. This preprocessing step helps in improving model performance, especially for algorithms sensitive to feature scaling, like neural networks.\n",
    "\n",
    " 5. Building a Neural Network Model\n",
    "```python\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_shape=(14, ), activation='sigmoid', name='dense_1'))\n",
    "model.add(Dense(64, activation='relu', name='dense_2'))\n",
    "model.add(Dense(64, activation='relu', name='dense_3'))\n",
    "model.add(Dense(64, activation='relu', name='dense_4'))\n",
    "model.add(Dense(64, activation='relu', name='dense_5'))\n",
    "model.add(Dense(1, activation='linear', name='dense_output'))\n",
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.001), loss='mse', metrics=['mae'])\n",
    "```\n",
    "- **Explanation:** This code defines a feedforward neural network model using `Sequential` from `tf.keras.models`. It consists of several fully connected (`Dense`) layers with different activation functions. The model is compiled with the RMSprop optimizer, mean squared error (MSE) loss function, and mean absolute error (MAE) metric.\n",
    "\n",
    "6. Training the Neural Network\n",
    "```python\n",
    "history = model.fit(X_train, y_train, batch_size=64, epochs=100, validation_split=0.02)\n",
    "```\n",
    "- **Explanation:** The `fit` method is used to train the neural network model (`model`) on the training data (`X_train`, `y_train`). Parameters like batch size (`64`), number of epochs (`100`), and validation split (`0.02`) are specified. The training process is stored in `history` for later analysis.\n",
    "\n",
    " 7. Model Evaluation\n",
    "```python\n",
    "mse_nn, mae_nn = model.evaluate(X_test, y_test)\n",
    "print('Mean squared error on test data: ', mse_nn)\n",
    "print('Mean absolute error on test data: ', mae_nn)\n",
    "```\n",
    "- **Explanation:** Finally, the trained model is evaluated using the test data (`X_test`, `y_test`) to compute mean squared error (MSE) and mean absolute error (MAE). The evaluation results (`mse_nn`, `mae_nn`) are printed to assess the model's performance on unseen data.\n",
    "\n",
    "Detailed Reasons for Using Each Component:\n",
    "- **Pandas and NumPy:** Used for data manipulation and processing.\n",
    "- **Scikit-Learn (`train_test_split`, `StandardScaler`):** Utilized for data splitting and feature scaling to prepare the data for training.\n",
    "- **TensorFlow and Keras (`Sequential`, `Dense`):** These libraries are used to define and build the neural network model for regression.\n",
    "- **Model Compilation (`compile`):** Specifies the optimizer, loss function, and metrics for training.\n",
    "- **Model Training (`fit`):** Trains the neural network model using the specified training data and parameters.\n",
    "- **Model Evaluation (`evaluate`):** Assesses the model's performance on unseen test data using evaluation metrics.\n",
    "\n",
    "Each component serves a specific purpose in the machine learning workflow, from data preprocessing and model building to training and evaluation, ultimately leading to the development of an effective predictive model.\n",
    "\n",
    "\n",
    "Assignment No: 1 =============================================================== \n",
    "Title: Linear regression by using Deep Neural network: Implement Boston housing price. Prediction problem by Linear regression using Deep Neural network. Use Boston House price prediction dataset. \n",
    "=====================================================================Objective: \n",
    "To learn about Deep Neural Network. \n",
    "To understand the concept of linear regressing in Deep Learning. \n",
    "Theory: \n",
    ". What is Linear Regression? \n",
    " Linear regression is useful for finding relationship between two continuous variables. \n",
    " Linear regression shows the linear relationship between the independent (predictor) variable i.e. Xaxis and the dependent (output) variable i.e. Yaxis, called linear regression. \n",
    " The above graph presents the linear relationship between the output(y) variable and predictor(X) variables.  The blue line is referred to as the best fit straight line. \n",
    " Linear regression using deep neural networks combines the principles of linear regression with the power of deep learning algorithms.  \n",
    " In this approach, the input features are passed through one or more layers of neurons to extract features and then a linear regression model is applied to the output of the last layer to make predictions. The weights and biases of the neural network are adjusted during training to optimize the performance of the model. \n",
    " This approach can be used for a variety of tasks, including predicting numerical values, such as stock prices or housing prices, and classifying data into categories, such as detecting whether an image contains a particular object or not. It is often used in fields such as finance, healthcare, and image recognition. \n",
    ". What is Deep Neural Network? \n",
    " A deep neural network is a type of machine learning algorithm that is modeled after the structure and function of the human brain. It consists of multiple layers of interconnected nodes, or artificial neurons that process data and learn from it to make predictions or classifications. \n",
    " Each layer of the network performs a specific type of processing on the data, such as identifying patterns or correlations between features, and passes the results to the next layer. The layers closest to the input are known as the \"input layer\", while the layers closest to the output are known as the \"output layer\". \n",
    " The intermediate layers between the input and output layers are known as \"hidden layers\". These layers are responsible for extracting increasingly complex features from the input data, and can be deep (i.e., containing many hidden layers) or shallow (i.e., containing only a few hidden layers). \n",
    " Deep neural networks are trained using a process known as back propagation, which involves adjusting the weights and biases of the nodes based on the error between the predicted output and the actual output. \n",
    " This process is repeated for multiple iterations until the model reaches an optimal level of accuracy.  \n",
    ". How Deep Neural Network works in Boston house price prediction \n",
    " Boston House Price Prediction is a common example used to illustrate how a deep neural network can work for regression tasks. The goal of this task is to predict the price of a house in Boston based on various features such as the number of rooms, crime rate, and accessibility to public transportation. \n",
    " Here's how a deep neural network can work for Boston House Price Prediction: \n",
    "1. Data preprocessing: The first step is to preprocess the data. This involves normalizing the input features to have a mean of 0 and a standard deviation of 1, which helps the network learn more efficiently. The dataset is then split into training and testing sets. \n",
    "2. Model architecture: A deep neural network is then defined with multiple layers. The first layer is the input layer, which takes in the normalized features. This is followed by several hidden layers, which can be deep or shallow. The last layer is the output layer, which predicts the house price. \n",
    "3. Model training: The model is then trained using the training set. During training, the weights and biases of the nodes are adjusted based on the error between the predicted \n",
    "output and the actual output. This is done using an optimization algorithm such as stochastic gradient descent. \n",
    "4. Model evaluation: Once the model is trained, it is evaluated using the testing set. The performance of the model is measured using metrics such as mean squared error or mean absolute error. \n",
    "5. Model prediction: Finally, the trained model can be used to make predictions on new data, such as predicting the price of a new house in Boston based on its features. \n",
    "6. By using a deep neural network for Boston House Price Prediction, we can obtain accurate predictions based on a large set of input features. This approach is scalable and can be used for other regression tasks as well. \n",
    ". Boston House Price Prediction Dataset \n",
    " Boston House Price Prediction is a wellknown dataset in machine learning and is often used to demonstrate regression analysis techniques. The dataset contains information about 506 houses in Boston, Massachusetts, USA. The goal is to predict the median value of owneroccupied homes in thousands of dollars. \n",
    " The dataset includes 13 input features, which are: \n",
    ". CRIM: per capita crime rate by town \n",
    ". ZN: proportion of residential land zoned for lots over 25,000 sq.ft. \n",
    ". INDUS: proportion of nonretail business acres per town \n",
    ". CHAS: Charles River dummy variable (1 if tract bounds river; 0 otherwise) \n",
    ". NOX: nitric oxides concentration (parts per 10 million) \n",
    ". RM: average number of rooms per dwelling \n",
    ". AGE: proportion of owneroccupied units built prior to 1940 \n",
    ". DIS: weighted distances to five Boston employment centers \n",
    ". RAD: index of accessibility to radial highways \n",
    ". TAX: fullvalue propertytax rate per $10,000 \n",
    ". PTRATIO: pupilteacher ratio by town \n",
    ". B: 1000(Bk  0.63)^2 where Bk is the proportion of black people by town \n",
    ". LSTAT: % lower status of the population \n",
    " The output variable is the median value of owneroccupied homes in thousands of dollars (MEDV). \n",
    " To predict the median value of owneroccupied homes, a regression model is trained on the dataset. The model can be a simple linear regression model or a more complex model, such as a deep neural network. \n",
    " After the model is trained, it can be used to predict the median value of owneroccupied homes based on the input features. The model's accuracy can be evaluated using metrics such as mean squared error or mean absolute error. \n",
    " Boston House Price Prediction is an example of regression analysis and is often used to teach machine learning concepts. The dataset is also used in research to compare the performance of different regression models. \n",
    "===================================================================== \n",
    "Conclusion: In this way we can Predict the Boston House Price using Deep Neural Network. "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
